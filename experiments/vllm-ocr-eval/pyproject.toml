[project]
name = "vllm-ocr-eval"
version = "0.1.0"
description = "OCR evaluation using vLLM for batch inference"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "vllm>=0.11.2",
    "torch>=2.0.0",
    "torchvision",
    "transformers>=4.40.0",
    "pillow",
    "pandas",
    "numpy",
    "scipy",
    "accelerate",
    "levenshtein",
    "json-repair>=0.25.0",
    "tabulate>=0.9.0",
    "addict>=2.4.0",
    "easydict>=1.13",
    "einops>=0.8.1",
    "timm>=1.0.22",
]

[project.optional-dependencies]
dev = ["jupyter"]

# Extra for DeepSeek-OCR compatibility.
# Use this when you want to run DeepSeek-OCR eval:
#   uv sync --extra deepseek-ocr
#
# This constrains transformers to a range where DeepSeek-OCR's
# custom modeling code (LlamaFlashAttention2, etc.) still exists.


[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["."]
exclude = [
    "*.tar",
    "train-00000/",
    "results/",
    "logs/",
    "__pycache__/",
    "*.pyc",
    ".venv/",
]

# For uv / hatch's dependency groups (optional but you already had this).
[dependency-groups]
dev = ["jupyter"]
